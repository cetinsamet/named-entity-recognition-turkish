{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --------------------------------------------------\n",
    "#\n",
    "# CRF1.ipynb\n",
    "#\n",
    "# Token features:\n",
    "#     (a) token (surface form)\n",
    "#\n",
    "# Written by cetinsamet -*- cetin.samet@metu.edu.tr\n",
    "# May, 2019\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import CRF\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filepath):\n",
    "\n",
    "    text     = []\n",
    "    sentence = []\n",
    "\n",
    "    with open(filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            word, _, _, _ = line.strip().split('\\t')\n",
    "\n",
    "            if word == '<S>':\n",
    "                text.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "\n",
    "            sentence.append(line.strip())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = readFile('data/train.txt')\n",
    "validText = readFile('data/valid.txt')\n",
    "testText  = readFile('data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature(token, token_index, sentence):\n",
    "\n",
    "    feature = {'token' : token}\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25736/25736 [00:00<00:00, 44647.07it/s]\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = []\n",
    "trainLabels   = []\n",
    "\n",
    "for sentence in tqdm(trainText):\n",
    "\n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, token in enumerate(sentence):\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        features.append(getFeature(word, i, sentence))\n",
    "        labels.append(label)\n",
    "    \n",
    "    trainFeatures.append(features)\n",
    "    trainLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6435/6435 [00:00<00:00, 25127.49it/s]\n"
     ]
    }
   ],
   "source": [
    "validFeatures = []\n",
    "validLabels   = []\n",
    "\n",
    "for sentence in tqdm(validText):\n",
    "    \n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, token in enumerate(sentence):\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        features.append(getFeature(word, i, sentence))\n",
    "        labels.append(label)\n",
    "    \n",
    "    validFeatures.append(features)\n",
    "    validLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3328/3328 [00:00<00:00, 49880.98it/s]\n"
     ]
    }
   ],
   "source": [
    "testFeatures = []\n",
    "testLabels   = []\n",
    "\n",
    "for sentence in tqdm(testText):\n",
    "    \n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, token in enumerate(sentence):\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        features.append(getFeature(word, i, sentence))\n",
    "        labels.append(label)\n",
    "    \n",
    "    testFeatures.append(features)\n",
    "    testLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalFeatures = trainFeatures + validFeatures\n",
    "trainvalLabels   = trainLabels   + validLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/cetinsamet/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed: 48.3min finished\n",
      "loading training data to CRFsuite: 100%|██████████| 32171/32171 [00:02<00:00, 11730.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 75320\n",
      "Seconds required: 0.672\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100747\n",
      "c2: 0.009646\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.70  loss=840897.89 active=75260 feature_norm=1.00\n",
      "Iter 2   time=2.00  loss=478493.44 active=75245 feature_norm=5.95\n",
      "Iter 3   time=0.38  loss=397970.44 active=74095 feature_norm=4.97\n",
      "Iter 4   time=1.72  loss=304593.99 active=75041 feature_norm=3.50\n",
      "Iter 5   time=0.39  loss=301300.81 active=75240 feature_norm=4.00\n",
      "Iter 6   time=0.40  loss=290595.76 active=75268 feature_norm=4.15\n",
      "Iter 7   time=0.36  loss=282419.68 active=58849 feature_norm=6.47\n",
      "Iter 8   time=0.35  loss=261314.14 active=75287 feature_norm=6.01\n",
      "Iter 9   time=0.33  loss=255918.85 active=74837 feature_norm=6.60\n",
      "Iter 10  time=0.33  loss=248841.33 active=59208 feature_norm=9.06\n",
      "Iter 11  time=0.33  loss=242756.01 active=59231 feature_norm=9.02\n",
      "Iter 12  time=0.33  loss=239508.08 active=59170 feature_norm=9.67\n",
      "Iter 13  time=0.41  loss=234366.38 active=59123 feature_norm=11.06\n",
      "Iter 14  time=0.33  loss=230288.53 active=69698 feature_norm=12.16\n",
      "Iter 15  time=0.38  loss=226287.84 active=69634 feature_norm=13.36\n",
      "Iter 16  time=0.31  loss=218658.22 active=65374 feature_norm=16.87\n",
      "Iter 17  time=0.39  loss=210070.12 active=64555 feature_norm=22.85\n",
      "Iter 18  time=0.37  loss=203028.40 active=64664 feature_norm=26.98\n",
      "Iter 19  time=0.48  loss=196910.71 active=64322 feature_norm=30.31\n",
      "Iter 20  time=0.34  loss=181169.15 active=65742 feature_norm=48.70\n",
      "Iter 21  time=0.74  loss=174671.60 active=64656 feature_norm=53.95\n",
      "Iter 22  time=0.33  loss=170394.15 active=66148 feature_norm=53.05\n",
      "Iter 23  time=0.34  loss=165661.79 active=65333 feature_norm=56.22\n",
      "Iter 24  time=0.34  loss=156245.83 active=64908 feature_norm=67.25\n",
      "Iter 25  time=0.38  loss=147513.07 active=64042 feature_norm=76.17\n",
      "Iter 26  time=0.41  loss=136297.62 active=63275 feature_norm=95.39\n",
      "Iter 27  time=0.43  loss=124344.64 active=61840 feature_norm=118.43\n",
      "Iter 28  time=0.36  loss=113021.13 active=62389 feature_norm=139.93\n",
      "Iter 29  time=0.36  loss=103479.32 active=61389 feature_norm=160.63\n",
      "Iter 30  time=0.34  loss=90794.21 active=60201 feature_norm=200.83\n",
      "Iter 31  time=0.37  loss=86248.89 active=57596 feature_norm=243.47\n",
      "Iter 32  time=0.46  loss=76384.60 active=61668 feature_norm=257.98\n",
      "Iter 33  time=0.40  loss=71477.89 active=58471 feature_norm=276.87\n",
      "Iter 34  time=1.61  loss=69197.16 active=57342 feature_norm=281.93\n",
      "Iter 35  time=0.38  loss=58221.53 active=56682 feature_norm=351.81\n",
      "Iter 36  time=0.39  loss=53568.42 active=56250 feature_norm=378.14\n",
      "Iter 37  time=0.34  loss=46461.87 active=55027 feature_norm=438.25\n",
      "Iter 38  time=0.34  loss=42465.09 active=55018 feature_norm=469.36\n",
      "Iter 39  time=0.42  loss=37317.73 active=54399 feature_norm=525.20\n",
      "Iter 40  time=1.39  loss=37154.15 active=54234 feature_norm=527.12\n",
      "Iter 41  time=0.38  loss=34742.19 active=54148 feature_norm=545.49\n",
      "Iter 42  time=0.41  loss=32893.21 active=53391 feature_norm=566.29\n",
      "Iter 43  time=0.36  loss=31112.89 active=52759 feature_norm=589.57\n",
      "Iter 44  time=2.28  loss=31076.70 active=52696 feature_norm=582.86\n",
      "Iter 45  time=0.34  loss=29439.63 active=52565 feature_norm=603.88\n",
      "Iter 46  time=0.34  loss=28484.99 active=52288 feature_norm=612.52\n",
      "Iter 47  time=0.34  loss=27904.71 active=51890 feature_norm=655.90\n",
      "Iter 48  time=0.32  loss=27312.23 active=50475 feature_norm=657.95\n",
      "Iter 49  time=0.31  loss=27152.10 active=50415 feature_norm=656.69\n",
      "Iter 50  time=0.30  loss=27025.32 active=50295 feature_norm=653.99\n",
      "Iter 51  time=0.30  loss=26893.54 active=50263 feature_norm=653.77\n",
      "Iter 52  time=0.30  loss=26610.64 active=49989 feature_norm=660.22\n",
      "Iter 53  time=0.30  loss=26481.63 active=49956 feature_norm=658.64\n",
      "Iter 54  time=0.30  loss=26264.27 active=49751 feature_norm=658.57\n",
      "Iter 55  time=0.29  loss=26147.29 active=49605 feature_norm=659.83\n",
      "Iter 56  time=0.29  loss=26006.42 active=42421 feature_norm=662.78\n",
      "Iter 57  time=0.63  loss=25950.60 active=41812 feature_norm=669.56\n",
      "Iter 58  time=0.32  loss=25834.96 active=41038 feature_norm=670.76\n",
      "Iter 59  time=0.30  loss=25748.04 active=40577 feature_norm=673.13\n",
      "Iter 60  time=0.42  loss=25628.74 active=39015 feature_norm=676.16\n",
      "Iter 61  time=0.41  loss=25561.42 active=38459 feature_norm=678.15\n",
      "Iter 62  time=0.35  loss=25485.93 active=37834 feature_norm=680.18\n",
      "Iter 63  time=0.35  loss=25412.38 active=36793 feature_norm=682.15\n",
      "Iter 64  time=0.35  loss=25340.21 active=36142 feature_norm=684.55\n",
      "Iter 65  time=0.53  loss=25270.89 active=35934 feature_norm=686.61\n",
      "Iter 66  time=0.42  loss=25203.56 active=35444 feature_norm=689.08\n",
      "Iter 67  time=0.49  loss=25149.81 active=35317 feature_norm=691.04\n",
      "Iter 68  time=0.37  loss=25100.25 active=35230 feature_norm=692.99\n",
      "Iter 69  time=0.37  loss=25056.58 active=35213 feature_norm=694.40\n",
      "Iter 70  time=0.44  loss=25018.07 active=35155 feature_norm=695.86\n",
      "Iter 71  time=0.41  loss=24988.33 active=35135 feature_norm=696.76\n",
      "Iter 72  time=0.36  loss=24963.92 active=35049 feature_norm=697.82\n",
      "Iter 73  time=0.45  loss=24943.10 active=35025 feature_norm=698.35\n",
      "Iter 74  time=0.36  loss=24923.20 active=34998 feature_norm=699.21\n",
      "Iter 75  time=0.36  loss=24901.99 active=34978 feature_norm=700.19\n",
      "Iter 76  time=0.35  loss=24885.81 active=34873 feature_norm=701.27\n",
      "Iter 77  time=0.33  loss=24871.00 active=34831 feature_norm=702.09\n",
      "Iter 78  time=0.32  loss=24857.51 active=34768 feature_norm=702.91\n",
      "Iter 79  time=0.31  loss=24841.61 active=34720 feature_norm=703.97\n",
      "Iter 80  time=0.31  loss=24830.21 active=34693 feature_norm=704.65\n",
      "Iter 81  time=0.30  loss=24818.25 active=34655 feature_norm=705.35\n",
      "Iter 82  time=0.30  loss=24809.17 active=34634 feature_norm=705.86\n",
      "Iter 83  time=0.30  loss=24800.08 active=34598 feature_norm=706.37\n",
      "Iter 84  time=0.30  loss=24791.90 active=34511 feature_norm=706.90\n",
      "Iter 85  time=0.30  loss=24782.52 active=34477 feature_norm=707.52\n",
      "Iter 86  time=0.30  loss=24774.08 active=34425 feature_norm=708.19\n",
      "Iter 87  time=0.30  loss=24766.92 active=34413 feature_norm=708.58\n",
      "Iter 88  time=0.29  loss=24759.49 active=34378 feature_norm=709.29\n",
      "Iter 89  time=0.29  loss=24752.73 active=34349 feature_norm=709.78\n",
      "Iter 90  time=0.30  loss=24746.15 active=34319 feature_norm=710.50\n",
      "Iter 91  time=0.32  loss=24740.87 active=34309 feature_norm=710.98\n",
      "Iter 92  time=0.32  loss=24735.77 active=34275 feature_norm=711.65\n",
      "Iter 93  time=0.31  loss=24731.16 active=34264 feature_norm=712.04\n",
      "Iter 94  time=0.32  loss=24726.92 active=34243 feature_norm=712.62\n",
      "Iter 95  time=0.31  loss=24723.55 active=34228 feature_norm=712.93\n",
      "Iter 96  time=0.32  loss=24720.11 active=34203 feature_norm=713.39\n",
      "Iter 97  time=0.32  loss=24717.45 active=34197 feature_norm=713.61\n",
      "Iter 98  time=0.31  loss=24714.70 active=34180 feature_norm=713.94\n",
      "Iter 99  time=0.34  loss=24712.13 active=34166 feature_norm=714.10\n",
      "Iter 100 time=0.56  loss=24709.68 active=34143 feature_norm=714.42\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 43.648\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 34143 (75320)\n",
      "Number of active attributes: 30681 (71438)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.363\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error...ne,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True),\n",
       "          fit_params=None, iid='warn', n_iter=35, n_jobs=-1,\n",
       "          param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1b03605cc0>, 'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1b0253e1d0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "          return_train_score='warn',\n",
       "          scoring=make_scorer(flat_f1_score, average=weighted), verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = CRF(  algorithm='lbfgs',\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True,\n",
    "            verbose=True)\n",
    "\n",
    "params_space = {'c1': scipy.stats.expon(scale=0.5),\n",
    "                'c2': scipy.stats.expon(scale=0.05)}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted')\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=35,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "\n",
    "rs.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.10074713030434022, 'c2': 0.009645981291748817}\n",
      "best CV score: 0.9462335278963963\n",
      "model size: 2.42M\n"
     ]
    }
   ],
   "source": [
    "# crf = rs.best_estimator_\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None,\n",
       "  c1=0.10074713030434022, c2=0.009645981291748817,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 32171/32171 [00:01<00:00, 20633.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 34673\n",
      "Seconds required: 0.292\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.048313\n",
      "c2: 0.028432\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.57  loss=840729.29 active=34648 feature_norm=1.00\n",
      "Iter 2   time=1.40  loss=477894.99 active=34626 feature_norm=5.94\n",
      "Iter 3   time=0.28  loss=397497.29 active=33524 feature_norm=4.97\n",
      "Iter 4   time=1.15  loss=304124.02 active=34378 feature_norm=3.51\n",
      "Iter 5   time=0.28  loss=300505.16 active=34624 feature_norm=3.99\n",
      "Iter 6   time=0.28  loss=289488.44 active=34634 feature_norm=4.18\n",
      "Iter 7   time=0.30  loss=287184.01 active=34613 feature_norm=6.96\n",
      "Iter 8   time=0.29  loss=258948.13 active=34648 feature_norm=6.18\n",
      "Iter 9   time=0.31  loss=254096.36 active=34663 feature_norm=6.80\n",
      "Iter 10  time=0.28  loss=243393.68 active=34641 feature_norm=8.29\n",
      "Iter 11  time=0.29  loss=233035.70 active=34610 feature_norm=12.52\n",
      "Iter 12  time=0.29  loss=226612.44 active=34644 feature_norm=12.65\n",
      "Iter 13  time=0.34  loss=223667.55 active=34665 feature_norm=13.23\n",
      "Iter 14  time=0.29  loss=220826.50 active=34652 feature_norm=15.40\n",
      "Iter 15  time=0.32  loss=218315.32 active=34664 feature_norm=15.41\n",
      "Iter 16  time=0.33  loss=216195.62 active=34661 feature_norm=16.13\n",
      "Iter 17  time=0.36  loss=211146.54 active=34663 feature_norm=17.87\n",
      "Iter 18  time=0.37  loss=198028.93 active=34655 feature_norm=24.23\n",
      "Iter 19  time=0.66  loss=194940.03 active=34659 feature_norm=29.10\n",
      "Iter 20  time=0.38  loss=183902.78 active=34664 feature_norm=34.37\n",
      "Iter 21  time=0.29  loss=172241.09 active=34660 feature_norm=43.77\n",
      "Iter 22  time=0.28  loss=167732.10 active=34659 feature_norm=54.78\n",
      "Iter 23  time=0.29  loss=160042.53 active=34661 feature_norm=51.60\n",
      "Iter 24  time=0.29  loss=154311.74 active=34670 feature_norm=54.71\n",
      "Iter 25  time=0.31  loss=151458.83 active=34668 feature_norm=56.55\n",
      "Iter 26  time=0.32  loss=146515.51 active=34651 feature_norm=73.28\n",
      "Iter 27  time=0.41  loss=141824.76 active=34665 feature_norm=77.42\n",
      "Iter 28  time=0.31  loss=136313.98 active=34671 feature_norm=76.69\n",
      "Iter 29  time=0.29  loss=132358.22 active=34667 feature_norm=80.63\n",
      "Iter 30  time=0.38  loss=126826.21 active=34647 feature_norm=101.95\n",
      "Iter 31  time=0.31  loss=115654.51 active=34647 feature_norm=110.48\n",
      "Iter 32  time=0.29  loss=109459.16 active=34655 feature_norm=120.63\n",
      "Iter 33  time=0.36  loss=103421.64 active=34615 feature_norm=134.92\n",
      "Iter 34  time=0.35  loss=95742.24 active=34649 feature_norm=155.85\n",
      "Iter 35  time=0.33  loss=88480.59 active=34648 feature_norm=172.71\n",
      "Iter 36  time=0.29  loss=82093.64 active=34643 feature_norm=192.96\n",
      "Iter 37  time=0.40  loss=74930.91 active=34652 feature_norm=216.26\n",
      "Iter 38  time=0.30  loss=67710.98 active=34663 feature_norm=246.17\n",
      "Iter 39  time=0.31  loss=61208.35 active=34660 feature_norm=272.08\n",
      "Iter 40  time=0.30  loss=54337.21 active=34660 feature_norm=306.29\n",
      "Iter 41  time=0.41  loss=47944.65 active=34664 feature_norm=339.16\n",
      "Iter 42  time=0.35  loss=43179.04 active=34659 feature_norm=370.68\n",
      "Iter 43  time=0.34  loss=41059.12 active=34655 feature_norm=380.92\n",
      "Iter 44  time=0.43  loss=38066.20 active=34653 feature_norm=396.95\n",
      "Iter 45  time=0.34  loss=34910.80 active=34650 feature_norm=421.58\n",
      "Iter 46  time=0.53  loss=32401.57 active=34614 feature_norm=442.62\n",
      "Iter 47  time=0.49  loss=30485.39 active=34580 feature_norm=465.47\n",
      "Iter 48  time=0.30  loss=29521.70 active=34576 feature_norm=487.41\n",
      "Iter 49  time=0.47  loss=28219.61 active=34620 feature_norm=490.63\n",
      "Iter 50  time=0.33  loss=27631.67 active=34619 feature_norm=495.67\n",
      "Iter 51  time=0.28  loss=26748.10 active=34535 feature_norm=508.22\n",
      "Iter 52  time=0.63  loss=26473.54 active=34577 feature_norm=516.01\n",
      "Iter 53  time=0.43  loss=26038.70 active=34579 feature_norm=522.44\n",
      "Iter 54  time=0.28  loss=25879.41 active=34584 feature_norm=527.35\n",
      "Iter 55  time=0.28  loss=25765.90 active=34605 feature_norm=527.79\n",
      "Iter 56  time=0.29  loss=25544.53 active=34566 feature_norm=527.79\n",
      "Iter 57  time=0.29  loss=25417.44 active=34506 feature_norm=527.36\n",
      "Iter 58  time=0.28  loss=25278.67 active=34539 feature_norm=526.30\n",
      "Iter 59  time=0.37  loss=25178.15 active=34539 feature_norm=525.91\n",
      "Iter 60  time=0.33  loss=25074.24 active=34461 feature_norm=525.22\n",
      "Iter 61  time=0.37  loss=24981.12 active=34471 feature_norm=525.88\n",
      "Iter 62  time=0.32  loss=24903.59 active=34464 feature_norm=526.52\n",
      "Iter 63  time=0.31  loss=24804.82 active=34431 feature_norm=527.83\n",
      "Iter 64  time=0.40  loss=24734.50 active=34438 feature_norm=528.48\n",
      "Iter 65  time=0.33  loss=24627.14 active=34411 feature_norm=529.91\n",
      "Iter 66  time=0.29  loss=24555.01 active=34412 feature_norm=530.49\n",
      "Iter 67  time=0.30  loss=24474.98 active=34378 feature_norm=531.45\n",
      "Iter 68  time=0.31  loss=24415.80 active=34369 feature_norm=532.12\n",
      "Iter 69  time=0.30  loss=24364.38 active=34359 feature_norm=532.42\n",
      "Iter 70  time=0.29  loss=24330.26 active=34383 feature_norm=532.64\n",
      "Iter 71  time=0.32  loss=24292.76 active=34383 feature_norm=532.79\n",
      "Iter 72  time=0.33  loss=24261.16 active=34373 feature_norm=532.98\n",
      "Iter 73  time=0.31  loss=24225.21 active=34373 feature_norm=533.24\n",
      "Iter 74  time=0.41  loss=24200.06 active=34376 feature_norm=533.37\n",
      "Iter 75  time=0.60  loss=24188.86 active=34363 feature_norm=533.36\n",
      "Iter 76  time=0.34  loss=24162.17 active=34365 feature_norm=533.45\n",
      "Iter 77  time=0.28  loss=24147.08 active=34360 feature_norm=533.48\n",
      "Iter 78  time=0.29  loss=24124.51 active=34342 feature_norm=533.50\n",
      "Iter 79  time=0.33  loss=24106.18 active=34346 feature_norm=533.40\n",
      "Iter 80  time=0.41  loss=24087.99 active=34345 feature_norm=533.32\n",
      "Iter 81  time=0.40  loss=24072.19 active=34314 feature_norm=533.36\n",
      "Iter 82  time=0.28  loss=24059.81 active=34306 feature_norm=533.34\n",
      "Iter 83  time=0.29  loss=24042.88 active=34294 feature_norm=533.40\n",
      "Iter 84  time=0.72  loss=24036.23 active=34290 feature_norm=533.49\n",
      "Iter 85  time=0.34  loss=24024.48 active=34290 feature_norm=533.54\n",
      "Iter 86  time=0.31  loss=24013.77 active=34279 feature_norm=533.56\n",
      "Iter 87  time=0.32  loss=24003.10 active=34279 feature_norm=533.60\n",
      "Iter 88  time=0.30  loss=23992.75 active=34283 feature_norm=533.58\n",
      "Iter 89  time=0.28  loss=23982.40 active=34285 feature_norm=533.65\n",
      "Iter 90  time=0.28  loss=23974.73 active=34287 feature_norm=533.63\n",
      "Iter 91  time=0.28  loss=23966.83 active=34288 feature_norm=533.73\n",
      "Iter 92  time=0.28  loss=23959.85 active=34285 feature_norm=533.75\n",
      "Iter 93  time=0.28  loss=23955.19 active=34285 feature_norm=533.84\n",
      "Iter 94  time=0.28  loss=23949.83 active=34279 feature_norm=533.87\n",
      "Iter 95  time=0.28  loss=23946.36 active=34277 feature_norm=533.93\n",
      "Iter 96  time=0.28  loss=23942.05 active=34275 feature_norm=533.98\n",
      "Iter 97  time=0.28  loss=23939.64 active=34272 feature_norm=534.04\n",
      "Iter 98  time=0.28  loss=23936.48 active=34274 feature_norm=534.07\n",
      "Iter 99  time=0.28  loss=23932.45 active=34273 feature_norm=534.13\n",
      "Iter 100 time=0.30  loss=23931.07 active=34273 feature_norm=534.16\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 35.837\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 34273 (34673)\n",
      "Number of active attributes: 30662 (30799)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.213\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None,\n",
       "  c1=0.04831323984330459, c2=0.028431668831944812,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved.\n"
     ]
    }
   ],
   "source": [
    "# SAVE CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/crf1.pickle', 'wb') as outfile:\n",
    "    pickle.dump(crf, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/crf1.pickle', 'rb') as infile:\n",
    "    crf = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TRAIN CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "ORGANIZATION       0.96      0.96      0.96      9034\n",
      "      PERSON       0.98      0.98      0.98     14476\n",
      "     PERCENT       1.00      1.00      1.00       617\n",
      "        DATE       0.95      0.96      0.95      3103\n",
      "    LOCATION       0.98      0.99      0.98      9409\n",
      "       MONEY       0.98      0.98      0.98       594\n",
      "        TIME       0.99      1.00      1.00       175\n",
      "\n",
      "   micro avg       0.97      0.98      0.97     37408\n",
      "   macro avg       0.97      0.98      0.97     37408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainvalPredLabels = crf.predict(trainvalFeatures)\n",
    "\n",
    "print(\"### TRAIN CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(trainvalLabels, trainvalPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TEST CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    LOCATION       0.88      0.74      0.80      1091\n",
      "ORGANIZATION       0.84      0.68      0.75       862\n",
      "      PERSON       0.78      0.58      0.66      1594\n",
      "       MONEY       0.88      0.76      0.82       113\n",
      "        DATE       0.85      0.80      0.82       364\n",
      "        TIME       1.00      0.43      0.61        23\n",
      "     PERCENT       0.99      0.94      0.97       107\n",
      "\n",
      "   micro avg       0.84      0.67      0.75      4154\n",
      "   macro avg       0.83      0.67      0.74      4154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredLabels  = crf.predict(testFeatures)\n",
    "\n",
    "print(\"### TEST CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(testLabels, testPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
