{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --------------------------------------------------\n",
    "#\n",
    "# logisticRegression.ipynb\n",
    "#\n",
    "# Written by cetinsamet -*- cetin.samet@metu.edu.tr\n",
    "# April, 2019\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from seqeval.metrics import classification_report\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filepath):\n",
    "    \n",
    "        text     = []\n",
    "        sentence = []\n",
    "\n",
    "        with open(filepath, 'r') as infile:\n",
    "            for line in infile:\n",
    "                word, _, _, _ = line.strip().split('\\t')\n",
    "\n",
    "                if word == '<S>':\n",
    "                    text.append(sentence)\n",
    "                    sentence = []\n",
    "                    continue\n",
    "\n",
    "                sentence.append(line.strip())\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = readFile('data/train.txt')\n",
    "validText = readFile('data/valid.txt')\n",
    "testText  = readFile('data/test.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = sio.loadmat('data/features.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = features['trainTokenFeatures']\n",
    "validFeatures = features['validTokenFeatures']\n",
    "testFeatures  = features['testTokenFeatures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = [[token.split('\\t')[-1] for token in sentence] for sentence in trainText]\n",
    "validLabels = [[token.split('\\t')[-1] for token in sentence] for sentence in validText]\n",
    "testLabels  = [[token.split('\\t')[-1] for token in sentence] for sentence in testText]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-DATE', 'B-LOCATION', 'B-MONEY', 'B-ORGANIZATION', 'B-PERCENT', 'B-PERSON', 'B-TIME', 'I-DATE', 'I-LOCATION', 'I-MONEY', 'I-ORGANIZATION', 'I-PERCENT', 'I-PERSON', 'I-TIME', 'O']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(np.unique([label for sentence in trainLabels for label in sentence]))\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabelsIdx = [[unique_labels.index(token.split('\\t')[-1]) for token in sentence] for sentence in trainLabels]\n",
    "validLabelsIdx = [[unique_labels.index(token.split('\\t')[-1]) for token in sentence] for sentence in validLabels]\n",
    "testLabelsIdx  = [[unique_labels.index(token.split('\\t')[-1]) for token in sentence] for sentence in testLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = trainFeatures\n",
    "y_train = np.asarray([label for sent in trainLabelsIdx for label in sent])\n",
    "\n",
    "x_valid = validFeatures\n",
    "y_valid = np.asarray([label for sent in validLabelsIdx for label in sent])\n",
    "\n",
    "x_test  = testFeatures\n",
    "y_test  = np.asarray([label for sent in testLabelsIdx for label in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = x_train.shape[0]\n",
    "n_valid = x_valid.shape[0]\n",
    "n_test  = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainval = np.vstack([x_train, x_valid])\n",
    "y_trainval = np.vstack([np.expand_dims(y_train, 1), np.expand_dims(y_valid, 1)]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid  = {\"C\":np.logspace(-3, 3, 7), \"penalty\":['l2']} # l1 lasso l2 ridge\n",
    "lr    = LogisticRegression(solver='lbfgs', random_state=123, verbose=True)\n",
    "lr_cv = GridSearchCV(lr, grid, cv = 3)\n",
    "lr_cv.fit(x_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2'}\n",
      "accuracy : 0.9105607195556349\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",lr_cv.best_params_)\n",
    "print(\"accuracy :\",lr_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', C=1.0, penalty='l2', random_state=123)\n",
    "lr.fit(x_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model is saved.\n"
     ]
    }
   ],
   "source": [
    "# SAVE LOGISTIC REGRESSION MODEL\n",
    "with open('model/logistic_regression.pickle', 'wb') as outfile:\n",
    "    pickle.dump(lr, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Logistic Regression model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LOGISTIC REGRESSION MODEL\n",
    "with open('model/logistic_regression.pickle', 'rb') as infile:\n",
    "    lr = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredIdx = lr.predict(x_train)\n",
    "\n",
    "trainPredLabel = []\n",
    "sent           = []\n",
    "ct             = 0\n",
    "\n",
    "for sentence in trainLabels:\n",
    "    for token in sentence:\n",
    "        sent.append(unique_labels[trainPredIdx[ct]])\n",
    "        ct += 1\n",
    "    trainPredLabel.axppend(sent)\n",
    "    sent = []\n",
    "print(\"### TRAIN CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(trainLabels, trainPredLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validPredIdx = lr.predict(x_valid)\n",
    "\n",
    "validPredLabel = []\n",
    "sent           = []\n",
    "ct             = 0\n",
    "\n",
    "for sentence in validLabels:\n",
    "    for token in sentence:\n",
    "        sent.append(unique_labels[validPredIdx[ct]])\n",
    "        ct += 1\n",
    "    validPredLabel.append(sent)\n",
    "    sent = []\n",
    "    \n",
    "print(\"### VALID CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(validLabels, validPredLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TEST CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERSON       0.35      0.25      0.29      1594\n",
      "ORGANIZATION       0.47      0.36      0.41       862\n",
      "    LOCATION       0.70      0.60      0.64      1091\n",
      "        DATE       0.57      0.51      0.54       364\n",
      "       MONEY       0.02      0.02      0.02       113\n",
      "     PERCENT       0.28      0.31      0.30       107\n",
      "        TIME       0.91      0.87      0.89        23\n",
      "\n",
      "   micro avg       0.48      0.38      0.43      4154\n",
      "   macro avg       0.48      0.38      0.43      4154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredIdx = lr.predict(x_test)\n",
    "\n",
    "testPredLabel = []\n",
    "sent          = []\n",
    "ct            = 0\n",
    "\n",
    "for sentence in testLabels:\n",
    "    for token in sentence:\n",
    "        sent.append(unique_labels[testPredIdx[ct]])\n",
    "        ct += 1\n",
    "    testPredLabel.append(sent)\n",
    "    sent = []\n",
    "    \n",
    "print(\"### TEST CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(testLabels, testPredLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
