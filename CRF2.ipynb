{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --------------------------------------------------\n",
    "#\n",
    "# CRF2.ipynb\n",
    "#\n",
    "# Token features:\n",
    "#     (a) token (surface form)\n",
    "#     (b) is_first           : is token at the beginning of the sentence?\n",
    "#     (c) is_last            : is token at the end of the sentence?\n",
    "#     (d) is_capitalized     : does token start with a capital letter? \n",
    "#     (e) is_all_capitalized : is all letters of the token capitalized?\n",
    "#     (f) is_capitals_inside : is there any capitalized letter inside the token?\n",
    "#     (g) is_numeric         : is token numeric?\n",
    "#     (h) is_numeric_inside  : is numeric characters inside the token?\n",
    "#     (i) is_alphanumeric    : is token alphanumeric?\n",
    "#\n",
    "# Written by cetinsamet -*- cetin.samet@metu.edu.tr\n",
    "# May, 2019\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import CRF\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filepath):\n",
    "\n",
    "    text     = []\n",
    "    sentence = []\n",
    "\n",
    "    with open(filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            word, _, _, _ = line.strip().split('\\t')\n",
    "\n",
    "            if word == '<S>':\n",
    "                text.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "\n",
    "            sentence.append(line.strip())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = readFile('data/train.txt')\n",
    "validText = readFile('data/valid.txt')\n",
    "testText  = readFile('data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature(token, token_index, sentence):\n",
    "\n",
    "    feature = {'token'             : token,\n",
    "               'is_first'          : token_index == 0,\n",
    "               'is_last'           : token_index == len(sentence) - 1,\n",
    "               \n",
    "               'is_capitalized'    : token[0].upper() == token[0],\n",
    "               'is_all_capitalized': token.upper() == token,\n",
    "               'is_capitals_inside': token[1:].lower() != token[1:],\n",
    "               'is_numeric'        : token.isdigit(),\n",
    "               'is_numeric_inside' : any([c.isdigit() for c in token]),\n",
    "               'is_alphanumeric'   : token.isalnum(),\n",
    "              }\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25736/25736 [00:01<00:00, 16148.51it/s]\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = []\n",
    "trainLabels   = []\n",
    "\n",
    "for sentence in tqdm(trainText):\n",
    "\n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, token in enumerate(sentence):\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        features.append(getFeature(word, i, sentence))\n",
    "        labels.append(label)\n",
    "    \n",
    "    trainFeatures.append(features)\n",
    "    trainLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6435/6435 [00:00<00:00, 14597.69it/s]\n"
     ]
    }
   ],
   "source": [
    "validFeatures = []\n",
    "validLabels   = []\n",
    "\n",
    "for sentence in tqdm(validText):\n",
    "    \n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, token in enumerate(sentence):\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        features.append(getFeature(word, i, sentence))\n",
    "        labels.append(label)\n",
    "    \n",
    "    validFeatures.append(features)\n",
    "    validLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatures = []\n",
    "testLabels   = []\n",
    "\n",
    "for sentence in tqdm(testText):\n",
    "    \n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, token in enumerate(sentence):\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        features.append(getFeature(word, i, sentence))\n",
    "        labels.append(label)\n",
    "    \n",
    "    testFeatures.append(features)\n",
    "    testLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalFeatures = trainFeatures + validFeatures\n",
    "trainvalLabels   = trainLabels   + validLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/cetinsamet/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 77.3min finished\n",
      "loading training data to CRFsuite: 100%|██████████| 32171/32171 [00:03<00:00, 9190.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 75440\n",
      "Seconds required: 0.851\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.048313\n",
      "c2: 0.028432\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.98  loss=717747.74 active=75417 feature_norm=1.00\n",
      "Iter 2   time=1.56  loss=445187.31 active=75259 feature_norm=4.70\n",
      "Iter 3   time=0.51  loss=370246.66 active=74430 feature_norm=4.04\n",
      "Iter 4   time=1.89  loss=273160.76 active=75052 feature_norm=2.85\n",
      "Iter 5   time=0.46  loss=264971.74 active=75319 feature_norm=3.37\n",
      "Iter 6   time=0.46  loss=249662.99 active=75335 feature_norm=3.50\n",
      "Iter 7   time=0.47  loss=222594.69 active=75312 feature_norm=5.35\n",
      "Iter 8   time=0.47  loss=204100.86 active=75378 feature_norm=5.43\n",
      "Iter 9   time=0.48  loss=192494.50 active=75407 feature_norm=6.25\n",
      "Iter 10  time=0.49  loss=179763.47 active=75417 feature_norm=7.51\n",
      "Iter 11  time=0.46  loss=167817.56 active=75409 feature_norm=8.94\n",
      "Iter 12  time=0.44  loss=158265.34 active=75355 feature_norm=10.66\n",
      "Iter 13  time=0.52  loss=151544.35 active=75397 feature_norm=11.21\n",
      "Iter 14  time=0.53  loss=145043.68 active=75342 feature_norm=12.40\n",
      "Iter 15  time=0.63  loss=139307.43 active=75339 feature_norm=13.67\n",
      "Iter 16  time=0.67  loss=132531.75 active=70712 feature_norm=15.31\n",
      "Iter 17  time=0.70  loss=125892.96 active=55716 feature_norm=18.40\n",
      "Iter 18  time=0.56  loss=118853.72 active=53248 feature_norm=21.58\n",
      "Iter 19  time=0.69  loss=111717.98 active=52340 feature_norm=26.21\n",
      "Iter 20  time=0.54  loss=106368.84 active=52349 feature_norm=28.69\n",
      "Iter 21  time=0.56  loss=100647.58 active=51877 feature_norm=34.52\n",
      "Iter 22  time=0.68  loss=97598.08 active=51881 feature_norm=35.87\n",
      "Iter 23  time=0.60  loss=92517.94 active=51589 feature_norm=39.38\n",
      "Iter 24  time=1.21  loss=88230.99 active=51453 feature_norm=42.57\n",
      "Iter 25  time=0.52  loss=84440.74 active=49979 feature_norm=45.42\n",
      "Iter 26  time=1.12  loss=82869.19 active=45532 feature_norm=53.85\n",
      "Iter 27  time=0.46  loss=76057.70 active=43943 feature_norm=58.20\n",
      "Iter 28  time=0.53  loss=73681.79 active=41890 feature_norm=63.76\n",
      "Iter 29  time=0.47  loss=69717.48 active=41533 feature_norm=67.39\n",
      "Iter 30  time=0.47  loss=66663.24 active=41232 feature_norm=73.94\n",
      "Iter 31  time=0.60  loss=63555.50 active=41043 feature_norm=82.39\n",
      "Iter 32  time=0.59  loss=59717.86 active=40892 feature_norm=91.56\n",
      "Iter 33  time=0.61  loss=56573.37 active=40532 feature_norm=102.04\n",
      "Iter 34  time=0.57  loss=52701.94 active=39973 feature_norm=115.22\n",
      "Iter 35  time=0.59  loss=48584.25 active=39845 feature_norm=130.53\n",
      "Iter 36  time=0.58  loss=44520.58 active=39645 feature_norm=149.35\n",
      "Iter 37  time=0.59  loss=40559.05 active=39393 feature_norm=168.57\n",
      "Iter 38  time=0.51  loss=36641.22 active=39258 feature_norm=190.97\n",
      "Iter 39  time=0.48  loss=32499.09 active=38799 feature_norm=216.46\n",
      "Iter 40  time=0.50  loss=28857.75 active=38400 feature_norm=243.65\n",
      "Iter 41  time=0.51  loss=25844.42 active=38080 feature_norm=269.13\n",
      "Iter 42  time=0.47  loss=23189.30 active=37825 feature_norm=297.21\n",
      "Iter 43  time=0.46  loss=21166.40 active=37599 feature_norm=321.27\n",
      "Iter 44  time=0.45  loss=19688.71 active=37144 feature_norm=341.34\n",
      "Iter 45  time=0.47  loss=18566.80 active=35732 feature_norm=356.61\n",
      "Iter 46  time=0.47  loss=17610.09 active=34660 feature_norm=370.00\n",
      "Iter 47  time=0.44  loss=16949.94 active=31960 feature_norm=380.03\n",
      "Iter 48  time=0.47  loss=16458.52 active=31454 feature_norm=387.71\n",
      "Iter 49  time=0.50  loss=16151.69 active=30887 feature_norm=393.07\n",
      "Iter 50  time=0.45  loss=15957.19 active=30468 feature_norm=394.66\n",
      "Iter 51  time=0.46  loss=15814.93 active=29409 feature_norm=396.05\n",
      "Iter 52  time=0.49  loss=15705.68 active=29034 feature_norm=396.92\n",
      "Iter 53  time=0.44  loss=15633.55 active=28780 feature_norm=397.82\n",
      "Iter 54  time=0.45  loss=15485.93 active=27729 feature_norm=401.89\n",
      "Iter 55  time=0.45  loss=15478.36 active=27526 feature_norm=401.26\n",
      "Iter 56  time=0.44  loss=15414.52 active=27557 feature_norm=401.73\n",
      "Iter 57  time=0.44  loss=15399.65 active=27521 feature_norm=401.94\n",
      "Iter 58  time=0.45  loss=15361.97 active=27265 feature_norm=402.44\n",
      "Iter 59  time=0.89  loss=15317.97 active=26708 feature_norm=402.88\n",
      "Iter 60  time=0.43  loss=15243.86 active=26195 feature_norm=404.50\n",
      "Iter 61  time=0.43  loss=15204.10 active=26026 feature_norm=404.88\n",
      "Iter 62  time=0.43  loss=15155.27 active=25768 feature_norm=405.44\n",
      "Iter 63  time=0.43  loss=15085.33 active=25351 feature_norm=406.56\n",
      "Iter 64  time=0.49  loss=15037.94 active=25274 feature_norm=406.78\n",
      "Iter 65  time=0.43  loss=14997.32 active=25193 feature_norm=407.26\n",
      "Iter 66  time=0.45  loss=14953.57 active=25081 feature_norm=407.89\n",
      "Iter 67  time=0.47  loss=14908.81 active=24999 feature_norm=408.42\n",
      "Iter 68  time=0.45  loss=14872.42 active=24949 feature_norm=408.74\n",
      "Iter 69  time=0.47  loss=14831.49 active=24877 feature_norm=409.29\n",
      "Iter 70  time=0.44  loss=14799.53 active=24831 feature_norm=409.59\n",
      "Iter 71  time=0.50  loss=14766.91 active=24734 feature_norm=410.05\n",
      "Iter 72  time=0.46  loss=14737.56 active=24695 feature_norm=410.33\n",
      "Iter 73  time=0.47  loss=14712.64 active=24653 feature_norm=410.67\n",
      "Iter 74  time=0.55  loss=14693.16 active=24616 feature_norm=410.87\n",
      "Iter 75  time=0.62  loss=14679.58 active=24603 feature_norm=411.04\n",
      "Iter 76  time=0.56  loss=14666.31 active=24574 feature_norm=411.16\n",
      "Iter 77  time=0.51  loss=14652.78 active=24550 feature_norm=411.26\n",
      "Iter 78  time=0.51  loss=14641.65 active=24520 feature_norm=411.34\n",
      "Iter 79  time=0.51  loss=14631.15 active=24514 feature_norm=411.45\n",
      "Iter 80  time=0.52  loss=14620.30 active=24493 feature_norm=411.48\n",
      "Iter 81  time=0.48  loss=14610.62 active=24468 feature_norm=411.56\n",
      "Iter 82  time=0.50  loss=14600.43 active=24452 feature_norm=411.55\n",
      "Iter 83  time=0.47  loss=14591.36 active=24438 feature_norm=411.58\n",
      "Iter 84  time=0.49  loss=14578.88 active=24429 feature_norm=411.57\n",
      "Iter 85  time=0.46  loss=14570.17 active=24410 feature_norm=411.64\n",
      "Iter 86  time=0.62  loss=14559.76 active=24414 feature_norm=411.59\n",
      "Iter 87  time=0.60  loss=14552.09 active=24408 feature_norm=411.62\n",
      "Iter 88  time=0.64  loss=14545.56 active=24405 feature_norm=411.61\n",
      "Iter 89  time=0.56  loss=14539.13 active=24395 feature_norm=411.66\n",
      "Iter 90  time=0.48  loss=14533.02 active=24396 feature_norm=411.66\n",
      "Iter 91  time=0.45  loss=14528.13 active=24384 feature_norm=411.70\n",
      "Iter 92  time=0.55  loss=14522.71 active=24380 feature_norm=411.68\n",
      "Iter 93  time=0.56  loss=14517.97 active=24367 feature_norm=411.72\n",
      "Iter 94  time=0.59  loss=14513.13 active=24350 feature_norm=411.69\n",
      "Iter 95  time=0.52  loss=14508.34 active=24341 feature_norm=411.71\n",
      "Iter 96  time=0.51  loss=14504.29 active=24345 feature_norm=411.70\n",
      "Iter 97  time=0.55  loss=14500.84 active=24338 feature_norm=411.74\n",
      "Iter 98  time=0.52  loss=14497.06 active=24340 feature_norm=411.70\n",
      "Iter 99  time=0.51  loss=14493.86 active=24326 feature_norm=411.73\n",
      "Iter 100 time=0.52  loss=14490.32 active=24318 feature_norm=411.73\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 55.683\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 24318 (75440)\n",
      "Number of active attributes: 20733 (71446)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.141\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error...ne,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True),\n",
       "          fit_params=None, iid='warn', n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1b084f99e8>, 'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1b084f9e10>},\n",
       "          pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "          return_train_score='warn',\n",
       "          scoring=make_scorer(flat_f1_score, average=weighted), verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = CRF(  algorithm='lbfgs',\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True,\n",
    "            verbose=True)\n",
    "\n",
    "params_space = {'c1': scipy.stats.expon(scale=0.5),\n",
    "                'c2': scipy.stats.expon(scale=0.05)}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted')\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=30,\n",
    "                        random_state=123,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None,\n",
       "  c1=0.04831323984330459, c2=0.028431668831944812,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crf.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved.\n"
     ]
    }
   ],
   "source": [
    "# SAVE CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/crf2.pickle', 'wb') as outfile:\n",
    "    pickle.dump(crf, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/crf2.pickle', 'rb') as infile:\n",
    "    crf = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalPredLabels = crf.predict(trainvalFeatures)\n",
    "\n",
    "print(\"### TRAINVAL CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(trainvalLabels, trainvalPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TEST CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "ORGANIZATION       0.81      0.76      0.78       862\n",
      "      PERSON       0.88      0.76      0.82      1594\n",
      "    LOCATION       0.82      0.83      0.82      1091\n",
      "     PERCENT       1.00      0.95      0.98       107\n",
      "        DATE       0.86      0.81      0.83       364\n",
      "        TIME       1.00      0.35      0.52        23\n",
      "       MONEY       0.86      0.73      0.79       113\n",
      "\n",
      "   micro avg       0.85      0.79      0.82      4154\n",
      "   macro avg       0.85      0.79      0.81      4154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredLabels  = crf.predict(testFeatures)\n",
    "\n",
    "print(\"### TEST CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(testLabels, testPredLabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
