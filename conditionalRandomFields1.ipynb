{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --------------------------------------------------\n",
    "#\n",
    "# conditionalRandomFields1.ipynb\n",
    "#\n",
    "# using only BERT token features\n",
    "#\n",
    "# Written by cetinsamet -*- cetin.samet@metu.edu.tr\n",
    "# April, 2019\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "from sklearn_crfsuite import CRF\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filepath):\n",
    "    \n",
    "        text     = []\n",
    "        sentence = []\n",
    "\n",
    "        with open(filepath, 'r') as infile:\n",
    "            for line in infile:\n",
    "                word, _, _, _ = line.strip().split('\\t')\n",
    "\n",
    "                if word == '<S>':\n",
    "                    text.append(sentence)\n",
    "                    sentence = []\n",
    "                    continue\n",
    "\n",
    "                sentence.append(line.strip())\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = readFile('data/train.txt')\n",
    "validText = readFile('data/valid.txt')\n",
    "testText  = readFile('data/test.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = sio.loadmat('data/features.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25736/25736 [04:40<00:00, 91.72it/s] \n"
     ]
    }
   ],
   "source": [
    "trainFeatures = []\n",
    "trainLabels   = []\n",
    "\n",
    "feats         = []\n",
    "labels        = []\n",
    "idx = 0\n",
    "for sentence in tqdm(trainText):\n",
    "    for token in sentence:\n",
    "        _, _, _, label = token.split('\\t')\n",
    "        d = dict(enumerate(features['trainTokenFeatures'][idx, :]))\n",
    "        d = {str(k): v for k, v in d.items()}\n",
    "        feats.append(d)\n",
    "        idx += 1\n",
    "        labels.append(label)\n",
    "        \n",
    "    trainFeatures.append(feats)\n",
    "    trainLabels.append(labels)\n",
    "    feats, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6435/6435 [01:51<00:00, 57.57it/s]\n"
     ]
    }
   ],
   "source": [
    "validFeatures = []\n",
    "validLabels   = []\n",
    "\n",
    "feats         = []\n",
    "labels        = []\n",
    "idx = 0\n",
    "for sentence in tqdm(validText):\n",
    "    for token in sentence:\n",
    "        _, _, _, label = token.split('\\t')\n",
    "        d = dict(enumerate(features['validTokenFeatures'][idx, :]))\n",
    "        d = {str(k): v for k, v in d.items()}\n",
    "        feats.append(d)\n",
    "        idx += 1\n",
    "        labels.append(label)\n",
    "        \n",
    "    validFeatures.append(feats)\n",
    "    validLabels.append(labels)\n",
    "    feats, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3328/3328 [00:38<00:00, 85.69it/s] \n"
     ]
    }
   ],
   "source": [
    "testFeatures = []\n",
    "testLabels   = []\n",
    "\n",
    "feats         = []\n",
    "labels        = []\n",
    "idx = 0\n",
    "for sentence in tqdm(testText):\n",
    "    for token in sentence:\n",
    "        _, _, _, label = token.split('\\t')\n",
    "        d = dict(enumerate(features['testTokenFeatures'][idx, :]))\n",
    "        d = {str(k): v for k, v in d.items()}\n",
    "        feats.append(d)\n",
    "        idx += 1\n",
    "        labels.append(label)\n",
    "        \n",
    "    testFeatures.append(feats)\n",
    "    testLabels.append(labels)\n",
    "    feats, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalFeatures = trainFeatures + validFeatures\n",
    "trainvalLabels   = trainLabels   + validLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 32171/32171 [11:37<00:00, 46.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 5720\n",
      "Seconds required: 57.927\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=42.28 loss=482055.99 active=5720  feature_norm=1.00\n",
      "Iter 2   time=22.55 loss=410786.36 active=5504  feature_norm=0.88\n",
      "Iter 3   time=95.79 loss=300130.29 active=4453  feature_norm=0.52\n",
      "Iter 4   time=23.49 loss=298583.42 active=5517  feature_norm=0.71\n",
      "Iter 5   time=25.11 loss=269510.08 active=5541  feature_norm=0.65\n",
      "Iter 6   time=25.37 loss=263547.12 active=5065  feature_norm=0.65\n",
      "Iter 7   time=24.53 loss=257666.52 active=5574  feature_norm=0.67\n",
      "Iter 8   time=23.92 loss=253458.70 active=5480  feature_norm=0.72\n",
      "Iter 9   time=23.56 loss=239491.47 active=5479  feature_norm=0.96\n",
      "Iter 10  time=23.48 loss=233584.55 active=5510  feature_norm=1.25\n",
      "Iter 11  time=22.41 loss=223533.45 active=5627  feature_norm=1.32\n",
      "Iter 12  time=23.28 loss=218955.18 active=5641  feature_norm=1.45\n",
      "Iter 13  time=19.56 loss=207689.40 active=5549  feature_norm=1.80\n",
      "Iter 14  time=18.50 loss=195067.19 active=5559  feature_norm=2.61\n",
      "Iter 15  time=19.10 loss=192711.65 active=5602  feature_norm=2.91\n",
      "Iter 16  time=20.01 loss=185856.68 active=5663  feature_norm=3.03\n",
      "Iter 17  time=18.94 loss=182516.07 active=5623  feature_norm=3.18\n",
      "Iter 18  time=19.20 loss=178621.71 active=5547  feature_norm=3.39\n",
      "Iter 19  time=19.93 loss=174455.61 active=5303  feature_norm=3.83\n",
      "Iter 20  time=19.81 loss=167142.42 active=5346  feature_norm=4.28\n",
      "Iter 21  time=19.58 loss=163892.49 active=5254  feature_norm=4.97\n",
      "Iter 22  time=19.11 loss=157008.79 active=5382  feature_norm=5.33\n",
      "Iter 23  time=20.84 loss=152960.91 active=5389  feature_norm=5.92\n",
      "Iter 24  time=19.64 loss=146391.43 active=5514  feature_norm=7.05\n",
      "Iter 25  time=20.40 loss=143880.60 active=5567  feature_norm=8.83\n",
      "Iter 26  time=19.05 loss=136980.70 active=5623  feature_norm=9.14\n",
      "Iter 27  time=20.29 loss=134442.77 active=5658  feature_norm=9.92\n",
      "Iter 28  time=20.55 loss=130414.72 active=5665  feature_norm=11.16\n",
      "Iter 29  time=19.00 loss=126445.35 active=5640  feature_norm=12.62\n",
      "Iter 30  time=18.61 loss=122569.04 active=5597  feature_norm=14.23\n",
      "Iter 31  time=20.52 loss=121428.54 active=5555  feature_norm=17.10\n",
      "Iter 32  time=19.91 loss=116710.09 active=5600  feature_norm=17.91\n",
      "Iter 33  time=19.62 loss=115598.26 active=5626  feature_norm=18.98\n",
      "Iter 34  time=18.71 loss=113678.02 active=5636  feature_norm=19.64\n",
      "Iter 35  time=17.28 loss=112467.15 active=5604  feature_norm=21.05\n",
      "Iter 36  time=20.71 loss=110668.18 active=5609  feature_norm=22.27\n",
      "Iter 37  time=19.92 loss=109680.50 active=5604  feature_norm=24.68\n",
      "Iter 38  time=18.31 loss=107680.44 active=5622  feature_norm=26.06\n",
      "Iter 39  time=18.13 loss=106782.60 active=5618  feature_norm=26.87\n",
      "Iter 40  time=15.80 loss=105422.76 active=5638  feature_norm=27.25\n",
      "Iter 41  time=9.98  loss=104308.75 active=5627  feature_norm=28.02\n",
      "Iter 42  time=13.32 loss=103151.45 active=5625  feature_norm=28.70\n",
      "Iter 43  time=18.72 loss=102488.15 active=5630  feature_norm=30.07\n",
      "Iter 44  time=18.47 loss=101205.26 active=5647  feature_norm=30.67\n",
      "Iter 45  time=18.57 loss=100653.12 active=5666  feature_norm=30.94\n",
      "Iter 46  time=19.07 loss=100083.50 active=5676  feature_norm=31.33\n",
      "Iter 47  time=14.87 loss=99934.71 active=5675  feature_norm=32.41\n",
      "Iter 48  time=10.31 loss=98897.37 active=5679  feature_norm=32.93\n",
      "Iter 49  time=12.53 loss=98391.99 active=5691  feature_norm=33.58\n",
      "Iter 50  time=12.10 loss=97800.67 active=5676  feature_norm=34.63\n",
      "Iter 51  time=36.18 loss=97203.01 active=5679  feature_norm=35.42\n",
      "Iter 52  time=20.03 loss=97011.38 active=5672  feature_norm=36.61\n",
      "Iter 53  time=18.57 loss=96303.36 active=5680  feature_norm=37.57\n",
      "Iter 54  time=18.02 loss=95898.00 active=5683  feature_norm=38.16\n",
      "Iter 55  time=16.15 loss=95486.25 active=5684  feature_norm=38.49\n",
      "Iter 56  time=20.00 loss=95220.57 active=5689  feature_norm=38.90\n",
      "Iter 57  time=19.78 loss=94951.03 active=5689  feature_norm=39.39\n",
      "Iter 58  time=20.01 loss=94700.21 active=5686  feature_norm=39.95\n",
      "Iter 59  time=19.51 loss=94363.04 active=5683  feature_norm=40.48\n",
      "Iter 60  time=21.18 loss=94057.03 active=5680  feature_norm=40.93\n",
      "Iter 61  time=20.59 loss=93766.48 active=5677  feature_norm=41.24\n",
      "Iter 62  time=20.58 loss=93524.87 active=5689  feature_norm=41.61\n",
      "Iter 63  time=20.90 loss=93277.74 active=5692  feature_norm=41.89\n",
      "Iter 64  time=19.23 loss=93037.08 active=5697  feature_norm=42.17\n",
      "Iter 65  time=19.07 loss=92803.08 active=5697  feature_norm=42.46\n",
      "Iter 66  time=19.05 loss=92597.99 active=5691  feature_norm=42.69\n",
      "Iter 67  time=18.76 loss=92411.08 active=5688  feature_norm=43.08\n",
      "Iter 68  time=18.61 loss=92216.69 active=5690  feature_norm=43.29\n",
      "Iter 69  time=19.16 loss=91998.66 active=5695  feature_norm=43.56\n",
      "Iter 70  time=18.18 loss=91803.49 active=5687  feature_norm=43.70\n",
      "Iter 71  time=19.26 loss=91597.97 active=5694  feature_norm=43.95\n",
      "Iter 72  time=18.32 loss=91457.45 active=5693  feature_norm=44.11\n",
      "Iter 73  time=18.84 loss=91233.61 active=5685  feature_norm=44.40\n",
      "Iter 74  time=20.26 loss=91090.19 active=5687  feature_norm=44.61\n",
      "Iter 75  time=19.43 loss=90922.30 active=5694  feature_norm=44.97\n",
      "Iter 76  time=18.84 loss=90782.93 active=5691  feature_norm=45.15\n",
      "Iter 77  time=19.97 loss=90561.56 active=5690  feature_norm=45.42\n",
      "Iter 78  time=19.80 loss=90408.46 active=5694  feature_norm=45.65\n",
      "Iter 79  time=20.40 loss=90233.35 active=5694  feature_norm=45.91\n",
      "Iter 80  time=19.68 loss=90103.47 active=5683  feature_norm=46.05\n",
      "Iter 81  time=18.30 loss=89924.16 active=5700  feature_norm=46.30\n",
      "Iter 82  time=17.95 loss=89797.13 active=5699  feature_norm=46.45\n",
      "Iter 83  time=18.52 loss=89627.21 active=5688  feature_norm=46.74\n",
      "Iter 84  time=18.36 loss=89503.67 active=5688  feature_norm=46.91\n",
      "Iter 85  time=19.41 loss=89311.50 active=5682  feature_norm=47.26\n",
      "Iter 86  time=18.23 loss=89177.28 active=5680  feature_norm=47.45\n",
      "Iter 87  time=19.46 loss=88992.08 active=5683  feature_norm=47.79\n",
      "Iter 88  time=19.18 loss=88817.40 active=5689  feature_norm=47.83\n",
      "Iter 89  time=18.46 loss=88625.14 active=5686  feature_norm=48.02\n",
      "Iter 90  time=16.72 loss=88538.31 active=5691  feature_norm=48.02\n",
      "Iter 91  time=12.04 loss=88360.86 active=5680  feature_norm=48.25\n",
      "Iter 92  time=10.48 loss=88200.51 active=5681  feature_norm=48.23\n",
      "Iter 93  time=11.92 loss=87966.89 active=5685  feature_norm=48.43\n",
      "Iter 94  time=14.69 loss=87859.18 active=5683  feature_norm=48.41\n",
      "Iter 95  time=12.30 loss=87674.91 active=5684  feature_norm=48.57\n",
      "Iter 96  time=10.19 loss=87577.88 active=5696  feature_norm=48.54\n",
      "Iter 97  time=12.45 loss=87406.83 active=5697  feature_norm=48.66\n",
      "Iter 98  time=10.56 loss=87320.90 active=5689  feature_norm=48.64\n",
      "Iter 99  time=14.31 loss=87186.17 active=5684  feature_norm=48.79\n",
      "Iter 100 time=20.38 loss=87097.42 active=5693  feature_norm=48.86\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 1977.045\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 5693 (5720)\n",
      "Number of active attributes: 603 (768)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.037\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Random Fields model is saved.\n"
     ]
    }
   ],
   "source": [
    "# SAVE CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/conditional_random_fields1.pickle', 'wb') as outfile:\n",
    "    pickle.dump(crf, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Conditional Random Fields model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/conditional_random_fields1.pickle', 'rb') as infile:\n",
    "    crf = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TRAIN CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE       0.70      0.83      0.76      2145\n",
      "      PERSON       0.31      0.57      0.40      5929\n",
      "    LOCATION       0.54      0.73      0.62      5789\n",
      "       MONEY       0.73      0.87      0.79       405\n",
      "ORGANIZATION       0.34      0.61      0.44      3924\n",
      "        TIME       0.97      0.98      0.97       154\n",
      "     PERCENT       0.99      0.98      0.98       527\n",
      "\n",
      "   micro avg       0.43      0.68      0.53     18873\n",
      "   macro avg       0.46      0.68      0.55     18873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainPredLabels = crf.predict(trainFeatures)\n",
    "\n",
    "print(\"### TRAIN CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(trainPredLabels, trainLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### VAL CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "ORGANIZATION       0.31      0.61      0.42      1005\n",
      "        DATE       0.71      0.81      0.76       480\n",
      "    LOCATION       0.57      0.69      0.63      1360\n",
      "      PERSON       0.38      0.66      0.48      1958\n",
      "     PERCENT       0.98      1.00      0.99        94\n",
      "       MONEY       0.79      0.88      0.83        99\n",
      "        TIME       0.95      1.00      0.97        18\n",
      "\n",
      "   micro avg       0.44      0.69      0.54      5014\n",
      "   macro avg       0.47      0.69      0.55      5014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validPredLabels = crf.predict(validFeatures)\n",
    "\n",
    "print(\"### VAL CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(validPredLabels, validLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TEST CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERSON       0.34      0.61      0.43       874\n",
      "ORGANIZATION       0.29      0.58      0.39       424\n",
      "    LOCATION       0.54      0.74      0.62       789\n",
      "        DATE       0.63      0.79      0.70       290\n",
      "     PERCENT       0.94      1.00      0.97       101\n",
      "       MONEY       0.66      0.86      0.75        87\n",
      "        TIME       0.87      0.87      0.87        23\n",
      "\n",
      "   micro avg       0.43      0.69      0.53      2588\n",
      "   macro avg       0.46      0.69      0.55      2588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredLabels  = crf.predict(testFeatures)\n",
    "\n",
    "print(\"### TEST CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(testPredLabels, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
