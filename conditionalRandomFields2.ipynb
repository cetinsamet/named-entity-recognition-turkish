{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --------------------------------------------------\n",
    "#\n",
    "# conditionalRandomFields2.ipynb\n",
    "#\n",
    "# using BERT's token and sentence features\n",
    "#\n",
    "# Written by cetinsamet -*- cetin.samet@metu.edu.tr\n",
    "# April, 2019\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "from sklearn_crfsuite import CRF\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filepath):\n",
    "    \n",
    "        text     = []\n",
    "        sentence = []\n",
    "\n",
    "        with open(filepath, 'r') as infile:\n",
    "            for line in infile:\n",
    "                word, _, _, _ = line.strip().split('\\t')\n",
    "\n",
    "                if word == '<S>':\n",
    "                    text.append(sentence)\n",
    "                    sentence = []\n",
    "                    continue\n",
    "\n",
    "                sentence.append(line.strip())\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = readFile('data/train.txt')\n",
    "validText = readFile('data/valid.txt')\n",
    "testText  = readFile('data/test.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = sio.loadmat('data/features.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = []\n",
    "trainLabels   = []\n",
    "\n",
    "feats         = []\n",
    "labels        = []\n",
    "\n",
    "tokenIdx      = 0\n",
    "sentenceIdx   = 0\n",
    "\n",
    "for sentence in tqdm(trainText):\n",
    "    \n",
    "    for token in sentence:\n",
    "        _, _, _, label = token.split('\\t')\n",
    "        feat = np.concatenate((features['trainTokenFeatures'][tokenIdx], features['trainSentFeatures'][sentenceIdx]))\n",
    "        d = dict(enumerate(feat))\n",
    "        d = {str(k): v for k, v in d.items()}\n",
    "        feats.append(d)\n",
    "        tokenIdx += 1\n",
    "        labels.append(label)\n",
    "        \n",
    "    trainFeatures.append(feats)\n",
    "    trainLabels.append(labels)\n",
    "    feats, labels = [], []\n",
    "    sentenceIdx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validFeatures = []\n",
    "validLabels   = []\n",
    "\n",
    "feats         = []\n",
    "labels        = []\n",
    "\n",
    "tokenIdx      = 0\n",
    "sentenceIdx   = 0\n",
    "\n",
    "for sentence in tqdm(validText):\n",
    "    \n",
    "    for token in sentence:\n",
    "        _, _, _, label = token.split('\\t')\n",
    "        feat = np.concatenate((features['validTokenFeatures'][tokenIdx], features['validSentFeatures'][sentenceIdx]))\n",
    "        d = dict(enumerate(feat))\n",
    "        d = {str(k): v for k, v in d.items()}\n",
    "        feats.append(d)\n",
    "        tokenIdx += 1\n",
    "        labels.append(label)\n",
    "        \n",
    "    validFeatures.append(feats)\n",
    "    validLabels.append(labels)\n",
    "    feats, labels = [], []\n",
    "    sentenceIdx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testFeatures = []\n",
    "testLabels   = []\n",
    "\n",
    "feats         = []\n",
    "labels        = []\n",
    "\n",
    "tokenIdx      = 0\n",
    "sentenceIdx   = 0\n",
    "\n",
    "for sentence in tqdm(testText):\n",
    "    \n",
    "    for token in sentence:\n",
    "        _, _, _, label = token.split('\\t')\n",
    "        feat = np.concatenate((features['testTokenFeatures'][tokenIdx], features['testSentFeatures'][sentenceIdx]))\n",
    "        d = dict(enumerate(feat))\n",
    "        d = {str(k): v for k, v in d.items()}\n",
    "        feats.append(d)\n",
    "        tokenIdx += 1\n",
    "        labels.append(label)\n",
    "        \n",
    "    testFeatures.append(feats)\n",
    "    testLabels.append(labels)\n",
    "    feats, labels = [], []\n",
    "    sentenceIdx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalFeatures = trainFeatures + validFeatures\n",
    "trainvalLabels   = trainLabels   + validLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/conditional_random_fields2.pickle', 'wb') as outfile:\n",
    "    pickle.dump(crf, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Conditional Random Fields model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/conditional_random_fields2.pickle', 'rb') as infile:\n",
    "    crf = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredLabels = crf.predict(trainFeatures)\n",
    "\n",
    "print(\"### TRAIN CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(trainLabels, trainPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validPredLabels = crf.predict(validFeatures)\n",
    "\n",
    "print(\"### VAL CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(validLabels, validPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TEST CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "ORGANIZATION       0.58      0.36      0.44       862\n",
      "      PERSON       0.61      0.38      0.47      1594\n",
      "       MONEY       0.77      0.54      0.64       113\n",
      "     PERCENT       0.99      0.94      0.97       107\n",
      "    LOCATION       0.70      0.50      0.58      1091\n",
      "        DATE       0.80      0.62      0.70       364\n",
      "        TIME       0.91      0.87      0.89        23\n",
      "\n",
      "   micro avg       0.67      0.45      0.54      4154\n",
      "   macro avg       0.66      0.45      0.53      4154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredLabels  = crf.predict(testFeatures)\n",
    "\n",
    "print(\"### TEST CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(testLabels, testPredLabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
