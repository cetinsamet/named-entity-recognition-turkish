{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --------------------------------------------------\n",
    "#\n",
    "# CRF7.ipynb\n",
    "#\n",
    "# (1) Token lemmatization using Zemberek TurkishMorphology  (DO NOT lemmatize tokens starting with uppercase letter)\n",
    "# (2) Token features:\n",
    "#     (a) token\n",
    "#     (b) is_first           : is token at the beginning of the sentence?\n",
    "#     (c) is_last            : is token at the end of the sentence?\n",
    "#     (d) is_capitalized     : does token start with a capital letter? \n",
    "#     (e) is_all_capitalized : is all letters of the token capitalized?\n",
    "#     (f) is_capitals_inside : is there any capitalized letter inside the token?\n",
    "#     (g) is_numeric         : is token numeric?\n",
    "#     (h) prefix-1           : first letter of the token\n",
    "#     (i) suffix-1           : last letter of the token\n",
    "#     (j) prefix-2           : first two letters of the token\n",
    "#     (k) suffix-2           : last two letters of the token\n",
    "#     (l) prefix-3           : first three letters of the token\n",
    "#     (m) suffix-3           : last three letters of the token\n",
    "#     (n) next-token         : following token\n",
    "#     (o) prev-token         : preceding token\n",
    "#\n",
    "# Written by cetinsamet -*- cetin.samet@metu.edu.tr\n",
    "# May, 2019\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import CRF\n",
    "import jpype as jp\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZEMBEREK_PATH = 'bin/zemberek-full.jar'\n",
    "\n",
    "# Start the JVM\n",
    "jp.startJVM(jp.getDefaultJVMPath(), '-ea', '-Djava.class.path=%s' % (ZEMBEREK_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TurkishMorphology = jp.JClass('zemberek.morphology.TurkishMorphology')\n",
    "morphology        = TurkishMorphology.createWithDefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filepath):\n",
    "\n",
    "    text     = []\n",
    "    sentence = []\n",
    "\n",
    "    with open(filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            word, _, _, _ = line.strip().split('\\t')\n",
    "\n",
    "            if word == '<S>':\n",
    "                text.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "\n",
    "            sentence.append(line.strip())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = readFile('data/train.txt')\n",
    "validText = readFile('data/valid.txt')\n",
    "testText  = readFile('data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature(token, token_index, sentence):\n",
    "\n",
    "    feature = {'token'             : token,\n",
    "               'is_first'          : token_index == 0,\n",
    "               'is_last'           : token_index == len(sentence) - 1,\n",
    "               \n",
    "               'is_capitalized'    : token[0].upper() == token[0],\n",
    "               'is_all_capitalized': token.upper() == token,\n",
    "               'is_capitals_inside': token[1:].lower() != token[1:],\n",
    "               'is_numeric'        : token.isdigit(),\n",
    "               \n",
    "               'prefix-1'          : token[0],\n",
    "               'suffix-1'          : token[-1],\n",
    "               \n",
    "               'prefix-2'          : '' if len(token) < 2  else token[:2],\n",
    "               'suffix-2'          : '' if len(token) < 2  else token[-2:],\n",
    "               \n",
    "               'prefix-3'          : '' if len(token) < 3  else token[:3],\n",
    "               'suffix-3'          : '' if len(token) < 3  else token[-3:],\n",
    "               \n",
    "               'prev-token'        : '' if token_index == 0 else sentence[token_index - 1][0],\n",
    "               'next-token'        : '' if token_index == len(sentence) - 1 else sentence[token_index + 1][0],\n",
    "              }\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = []\n",
    "trainLabels   = []\n",
    "\n",
    "for sentence in trainText:\n",
    "    SENT     = []\n",
    "    features = []\n",
    "    labels   = []\n",
    "    for token in sentence:\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        if word[0] == word[0].upper():\n",
    "            root = word\n",
    "        else:\n",
    "            results = morphology.analyze(word).analysisResults\n",
    "            root    = results[0].getLemmas()[0] if results else word\n",
    "        SENT.append(root)\n",
    "        labels.append(label)\n",
    "        \n",
    "    for i, word in enumerate(SENT):\n",
    "        features.append(getFeature(word, i, SENT))\n",
    "    \n",
    "    trainFeatures.append(features)\n",
    "    trainLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validFeatures = []\n",
    "validLabels   = []\n",
    "\n",
    "for sentence in validText:\n",
    "    SENT     = []\n",
    "    features = []\n",
    "    labels   = []\n",
    "    for token in sentence:\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        if word[0] == word[0].upper():\n",
    "            root = word\n",
    "        else:\n",
    "            results = morphology.analyze(word).analysisResults\n",
    "            root    = results[0].getLemmas()[0] if results else word\n",
    "        SENT.append(root)\n",
    "        labels.append(label)\n",
    "        \n",
    "    for i, word in enumerate(SENT):\n",
    "        features.append(getFeature(word, i, SENT))\n",
    "    \n",
    "    validFeatures.append(features)\n",
    "    validLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatures = []\n",
    "testLabels   = []\n",
    "\n",
    "for sentence in testText:\n",
    "    SENT     = []\n",
    "    features = []\n",
    "    labels   = []\n",
    "    for token in sentence:\n",
    "        word, _, _, label = token.split('\\t')\n",
    "        \n",
    "        if word[0] == word[0].upper():\n",
    "            root = word\n",
    "        else:\n",
    "            results = morphology.analyze(word).analysisResults\n",
    "            root    = results[0].getLemmas()[0] if results else word\n",
    "        SENT.append(root)\n",
    "        labels.append(label)\n",
    "        \n",
    "    for i, word in enumerate(SENT):\n",
    "        features.append(getFeature(word, i, SENT))\n",
    "    \n",
    "    testFeatures.append(features)\n",
    "    testLabels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalFeatures = trainFeatures + validFeatures\n",
    "trainvalLabels   = trainLabels   + validLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/cetinsamet/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 161.2min finished\n",
      "loading training data to CRFsuite: 100%|██████████| 32171/32171 [00:05<00:00, 6398.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 65615\n",
      "Seconds required: 1.289\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.128642\n",
      "c2: 0.040072\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=1.12  loss=764334.27 active=65300 feature_norm=1.00\n",
      "Iter 2   time=1.74  loss=527749.14 active=64852 feature_norm=6.28\n",
      "Iter 3   time=0.59  loss=416419.56 active=61464 feature_norm=5.37\n",
      "Iter 4   time=3.54  loss=251852.06 active=62942 feature_norm=3.94\n",
      "Iter 5   time=1.77  loss=232081.03 active=64546 feature_norm=3.76\n",
      "Iter 6   time=0.57  loss=213047.20 active=64956 feature_norm=4.23\n",
      "Iter 7   time=0.57  loss=180184.87 active=64471 feature_norm=5.58\n",
      "Iter 8   time=0.57  loss=146714.05 active=60869 feature_norm=8.47\n",
      "Iter 9   time=0.57  loss=134546.59 active=61444 feature_norm=9.91\n",
      "Iter 10  time=0.57  loss=129311.38 active=61657 feature_norm=10.20\n",
      "Iter 11  time=0.56  loss=115125.07 active=60594 feature_norm=11.77\n",
      "Iter 12  time=0.58  loss=101143.26 active=60282 feature_norm=13.70\n",
      "Iter 13  time=0.62  loss=88528.13 active=59725 feature_norm=16.74\n",
      "Iter 14  time=0.60  loss=78079.58 active=59078 feature_norm=20.23\n",
      "Iter 15  time=0.57  loss=69999.25 active=58917 feature_norm=22.44\n",
      "Iter 16  time=0.57  loss=65300.16 active=58708 feature_norm=24.62\n",
      "Iter 17  time=0.60  loss=61463.03 active=57901 feature_norm=30.09\n",
      "Iter 18  time=0.59  loss=57459.74 active=58192 feature_norm=30.81\n",
      "Iter 19  time=0.60  loss=55461.47 active=58073 feature_norm=32.44\n",
      "Iter 20  time=0.60  loss=50921.58 active=57663 feature_norm=37.21\n",
      "Iter 21  time=0.57  loss=46232.03 active=57210 feature_norm=44.18\n",
      "Iter 22  time=0.63  loss=42705.48 active=56887 feature_norm=50.80\n",
      "Iter 23  time=0.61  loss=39733.01 active=56570 feature_norm=56.33\n",
      "Iter 24  time=0.58  loss=36267.25 active=55578 feature_norm=64.98\n",
      "Iter 25  time=0.57  loss=33360.50 active=54206 feature_norm=73.49\n",
      "Iter 26  time=0.56  loss=30900.51 active=53280 feature_norm=80.78\n",
      "Iter 27  time=0.59  loss=28604.67 active=52848 feature_norm=88.24\n",
      "Iter 28  time=0.57  loss=26102.58 active=51952 feature_norm=98.25\n",
      "Iter 29  time=0.57  loss=24241.93 active=50616 feature_norm=107.26\n",
      "Iter 30  time=0.61  loss=22523.89 active=49397 feature_norm=116.67\n",
      "Iter 31  time=0.60  loss=21122.04 active=49168 feature_norm=125.39\n",
      "Iter 32  time=0.58  loss=19710.20 active=48509 feature_norm=136.68\n",
      "Iter 33  time=0.58  loss=18844.30 active=48452 feature_norm=145.27\n",
      "Iter 34  time=0.59  loss=17868.45 active=47850 feature_norm=153.05\n",
      "Iter 35  time=0.64  loss=17081.66 active=46420 feature_norm=160.06\n",
      "Iter 36  time=0.59  loss=16139.31 active=45806 feature_norm=169.15\n",
      "Iter 37  time=0.60  loss=15481.48 active=45379 feature_norm=175.50\n",
      "Iter 38  time=0.64  loss=14889.82 active=45082 feature_norm=182.99\n",
      "Iter 39  time=0.59  loss=14407.00 active=44136 feature_norm=190.06\n",
      "Iter 40  time=0.57  loss=14037.35 active=43300 feature_norm=196.56\n",
      "Iter 41  time=0.58  loss=13729.24 active=42514 feature_norm=202.22\n",
      "Iter 42  time=0.57  loss=13484.04 active=41799 feature_norm=207.07\n",
      "Iter 43  time=0.57  loss=13301.06 active=41047 feature_norm=211.46\n",
      "Iter 44  time=0.57  loss=13154.59 active=40857 feature_norm=213.41\n",
      "Iter 45  time=0.57  loss=13049.26 active=40694 feature_norm=215.38\n",
      "Iter 46  time=0.57  loss=12947.27 active=40242 feature_norm=217.27\n",
      "Iter 47  time=0.64  loss=12874.51 active=39545 feature_norm=218.79\n",
      "Iter 48  time=0.59  loss=12806.64 active=39163 feature_norm=219.91\n",
      "Iter 49  time=0.58  loss=12742.40 active=38506 feature_norm=220.75\n",
      "Iter 50  time=0.57  loss=12684.36 active=38117 feature_norm=221.28\n",
      "Iter 51  time=0.57  loss=12633.10 active=37557 feature_norm=221.85\n",
      "Iter 52  time=0.61  loss=12587.96 active=37331 feature_norm=222.28\n",
      "Iter 53  time=0.59  loss=12546.17 active=37023 feature_norm=222.99\n",
      "Iter 54  time=0.61  loss=12511.24 active=36747 feature_norm=223.45\n",
      "Iter 55  time=0.62  loss=12480.41 active=36530 feature_norm=224.05\n",
      "Iter 56  time=0.58  loss=12451.20 active=36247 feature_norm=224.38\n",
      "Iter 57  time=0.57  loss=12423.33 active=35916 feature_norm=224.94\n",
      "Iter 58  time=0.57  loss=12397.78 active=35746 feature_norm=225.22\n",
      "Iter 59  time=0.58  loss=12376.45 active=35503 feature_norm=225.64\n",
      "Iter 60  time=0.57  loss=12354.88 active=35318 feature_norm=225.81\n",
      "Iter 61  time=0.57  loss=12334.88 active=35049 feature_norm=226.15\n",
      "Iter 62  time=0.57  loss=12316.77 active=34743 feature_norm=226.33\n",
      "Iter 63  time=0.59  loss=12302.45 active=34599 feature_norm=226.63\n",
      "Iter 64  time=0.59  loss=12288.02 active=34450 feature_norm=226.72\n",
      "Iter 65  time=0.57  loss=12274.76 active=34294 feature_norm=226.88\n",
      "Iter 66  time=0.57  loss=12261.11 active=34136 feature_norm=226.93\n",
      "Iter 67  time=0.60  loss=12248.73 active=33967 feature_norm=227.04\n",
      "Iter 68  time=0.57  loss=12237.85 active=33872 feature_norm=227.04\n",
      "Iter 69  time=0.59  loss=12227.75 active=33737 feature_norm=227.10\n",
      "Iter 70  time=0.62  loss=12217.71 active=33632 feature_norm=227.06\n",
      "Iter 71  time=0.61  loss=12207.65 active=33523 feature_norm=227.07\n",
      "Iter 72  time=0.61  loss=12198.46 active=33413 feature_norm=226.99\n",
      "Iter 73  time=0.59  loss=12189.06 active=33277 feature_norm=226.98\n",
      "Iter 74  time=0.57  loss=12180.30 active=33153 feature_norm=226.86\n",
      "Iter 75  time=0.57  loss=12171.44 active=33035 feature_norm=226.84\n",
      "Iter 76  time=0.58  loss=12163.38 active=32927 feature_norm=226.75\n",
      "Iter 77  time=0.58  loss=12154.97 active=32855 feature_norm=226.71\n",
      "Iter 78  time=0.61  loss=12147.35 active=32788 feature_norm=226.60\n",
      "Iter 79  time=0.57  loss=12139.24 active=32703 feature_norm=226.56\n",
      "Iter 80  time=0.57  loss=12132.11 active=32587 feature_norm=226.45\n",
      "Iter 81  time=0.64  loss=12124.76 active=32505 feature_norm=226.42\n",
      "Iter 82  time=0.60  loss=12118.21 active=32435 feature_norm=226.32\n",
      "Iter 83  time=0.57  loss=12111.42 active=32337 feature_norm=226.30\n",
      "Iter 84  time=0.57  loss=12105.19 active=32226 feature_norm=226.21\n",
      "Iter 85  time=0.60  loss=12099.16 active=32152 feature_norm=226.22\n",
      "Iter 86  time=0.57  loss=12093.59 active=32085 feature_norm=226.14\n",
      "Iter 87  time=0.57  loss=12088.08 active=32044 feature_norm=226.16\n",
      "Iter 88  time=0.61  loss=12082.73 active=31967 feature_norm=226.11\n",
      "Iter 89  time=0.62  loss=12077.54 active=31865 feature_norm=226.13\n",
      "Iter 90  time=0.65  loss=12072.61 active=31818 feature_norm=226.07\n",
      "Iter 91  time=0.59  loss=12067.75 active=31774 feature_norm=226.13\n",
      "Iter 92  time=0.57  loss=12063.20 active=31744 feature_norm=226.10\n",
      "Iter 93  time=0.57  loss=12058.69 active=31702 feature_norm=226.14\n",
      "Iter 94  time=0.57  loss=12054.67 active=31653 feature_norm=226.12\n",
      "Iter 95  time=0.58  loss=12051.11 active=31608 feature_norm=226.19\n",
      "Iter 96  time=0.57  loss=12046.47 active=31570 feature_norm=226.18\n",
      "Iter 97  time=0.57  loss=12042.66 active=31541 feature_norm=226.24\n",
      "Iter 98  time=0.63  loss=12039.04 active=31504 feature_norm=226.24\n",
      "Iter 99  time=0.61  loss=12036.00 active=31446 feature_norm=226.29\n",
      "Iter 100 time=0.58  loss=12032.67 active=31386 feature_norm=226.29\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 64.622\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 31386 (65615)\n",
      "Number of active attributes: 18964 (45741)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.113\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error...ne,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1afba58a58>, 'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11128f358>},\n",
       "          pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "          return_train_score='warn',\n",
       "          scoring=make_scorer(flat_f1_score, average=weighted), verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = CRF(  algorithm='lbfgs',\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True,\n",
    "            verbose=True)\n",
    "\n",
    "params_space = {'c1': scipy.stats.expon(scale=0.5),\n",
    "                'c2': scipy.stats.expon(scale=0.05)}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted')\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        random_state=123,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.1286420400585254, 'c2': 0.040071684090734375}\n",
      "best CV score: 0.9680107799007583\n",
      "model size: 1.71M\n"
     ]
    }
   ],
   "source": [
    "# crf = rs.best_estimator_\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None,\n",
       "  c1=0.1286420400585254, c2=0.040071684090734375,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 32171/32171 [00:07<00:00, 4414.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 65615\n",
      "Seconds required: 1.532\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.128642\n",
      "c2: 0.040072\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=1.23  loss=764334.27 active=65300 feature_norm=1.00\n",
      "Iter 2   time=1.76  loss=527749.14 active=64852 feature_norm=6.28\n",
      "Iter 3   time=0.60  loss=416419.56 active=61464 feature_norm=5.37\n",
      "Iter 4   time=3.81  loss=251852.06 active=62942 feature_norm=3.94\n",
      "Iter 5   time=1.86  loss=232081.03 active=64546 feature_norm=3.76\n",
      "Iter 6   time=0.58  loss=213047.20 active=64956 feature_norm=4.23\n",
      "Iter 7   time=0.58  loss=180184.87 active=64471 feature_norm=5.58\n",
      "Iter 8   time=0.60  loss=146714.05 active=60869 feature_norm=8.47\n",
      "Iter 9   time=0.58  loss=134546.59 active=61444 feature_norm=9.91\n",
      "Iter 10  time=0.58  loss=129311.38 active=61657 feature_norm=10.20\n",
      "Iter 11  time=0.58  loss=115125.07 active=60594 feature_norm=11.77\n",
      "Iter 12  time=0.60  loss=101143.26 active=60282 feature_norm=13.70\n",
      "Iter 13  time=0.59  loss=88528.13 active=59725 feature_norm=16.74\n",
      "Iter 14  time=0.63  loss=78079.58 active=59078 feature_norm=20.23\n",
      "Iter 15  time=0.59  loss=69999.25 active=58917 feature_norm=22.44\n",
      "Iter 16  time=0.58  loss=65300.16 active=58708 feature_norm=24.62\n",
      "Iter 17  time=0.63  loss=61463.03 active=57901 feature_norm=30.09\n",
      "Iter 18  time=0.67  loss=57459.74 active=58192 feature_norm=30.81\n",
      "Iter 19  time=0.72  loss=55461.47 active=58073 feature_norm=32.44\n",
      "Iter 20  time=0.67  loss=50921.58 active=57663 feature_norm=37.21\n",
      "Iter 21  time=0.64  loss=46232.03 active=57210 feature_norm=44.18\n",
      "Iter 22  time=0.61  loss=42705.48 active=56887 feature_norm=50.80\n",
      "Iter 23  time=0.61  loss=39733.01 active=56570 feature_norm=56.33\n",
      "Iter 24  time=0.60  loss=36267.25 active=55578 feature_norm=64.98\n",
      "Iter 25  time=0.61  loss=33360.50 active=54206 feature_norm=73.49\n",
      "Iter 26  time=0.58  loss=30900.51 active=53280 feature_norm=80.78\n",
      "Iter 27  time=0.61  loss=28604.67 active=52848 feature_norm=88.24\n",
      "Iter 28  time=0.58  loss=26102.58 active=51952 feature_norm=98.25\n",
      "Iter 29  time=0.64  loss=24241.93 active=50616 feature_norm=107.26\n",
      "Iter 30  time=0.60  loss=22523.89 active=49397 feature_norm=116.67\n",
      "Iter 31  time=0.59  loss=21122.04 active=49168 feature_norm=125.39\n",
      "Iter 32  time=0.58  loss=19710.20 active=48509 feature_norm=136.68\n",
      "Iter 33  time=0.61  loss=18844.30 active=48452 feature_norm=145.27\n",
      "Iter 34  time=0.66  loss=17868.45 active=47850 feature_norm=153.05\n",
      "Iter 35  time=0.66  loss=17081.66 active=46420 feature_norm=160.06\n",
      "Iter 36  time=0.65  loss=16139.31 active=45806 feature_norm=169.15\n",
      "Iter 37  time=0.69  loss=15481.48 active=45379 feature_norm=175.50\n",
      "Iter 38  time=0.64  loss=14889.82 active=45082 feature_norm=182.99\n",
      "Iter 39  time=0.63  loss=14407.00 active=44136 feature_norm=190.06\n",
      "Iter 40  time=0.60  loss=14037.35 active=43300 feature_norm=196.56\n",
      "Iter 41  time=0.59  loss=13729.24 active=42514 feature_norm=202.22\n",
      "Iter 42  time=0.61  loss=13484.04 active=41799 feature_norm=207.07\n",
      "Iter 43  time=0.59  loss=13301.06 active=41047 feature_norm=211.46\n",
      "Iter 44  time=0.68  loss=13154.59 active=40857 feature_norm=213.41\n",
      "Iter 45  time=0.63  loss=13049.26 active=40694 feature_norm=215.38\n",
      "Iter 46  time=0.62  loss=12947.27 active=40242 feature_norm=217.27\n",
      "Iter 47  time=0.58  loss=12874.51 active=39545 feature_norm=218.79\n",
      "Iter 48  time=0.60  loss=12806.64 active=39163 feature_norm=219.91\n",
      "Iter 49  time=0.60  loss=12742.40 active=38506 feature_norm=220.75\n",
      "Iter 50  time=0.66  loss=12684.36 active=38117 feature_norm=221.28\n",
      "Iter 51  time=0.67  loss=12633.10 active=37557 feature_norm=221.85\n",
      "Iter 52  time=0.69  loss=12587.96 active=37331 feature_norm=222.28\n",
      "Iter 53  time=0.61  loss=12546.17 active=37023 feature_norm=222.99\n",
      "Iter 54  time=0.58  loss=12511.24 active=36747 feature_norm=223.45\n",
      "Iter 55  time=0.63  loss=12480.41 active=36530 feature_norm=224.05\n",
      "Iter 56  time=0.60  loss=12451.20 active=36247 feature_norm=224.38\n",
      "Iter 57  time=0.58  loss=12423.33 active=35916 feature_norm=224.94\n",
      "Iter 58  time=0.60  loss=12397.78 active=35746 feature_norm=225.22\n",
      "Iter 59  time=0.58  loss=12376.45 active=35503 feature_norm=225.64\n",
      "Iter 60  time=0.59  loss=12354.88 active=35318 feature_norm=225.81\n",
      "Iter 61  time=0.64  loss=12334.88 active=35049 feature_norm=226.15\n",
      "Iter 62  time=0.60  loss=12316.77 active=34743 feature_norm=226.33\n",
      "Iter 63  time=0.59  loss=12302.45 active=34599 feature_norm=226.63\n",
      "Iter 64  time=0.59  loss=12288.02 active=34450 feature_norm=226.72\n",
      "Iter 65  time=0.59  loss=12274.76 active=34294 feature_norm=226.88\n",
      "Iter 66  time=0.60  loss=12261.11 active=34136 feature_norm=226.93\n",
      "Iter 67  time=0.64  loss=12248.73 active=33967 feature_norm=227.04\n",
      "Iter 68  time=0.70  loss=12237.85 active=33872 feature_norm=227.04\n",
      "Iter 69  time=0.69  loss=12227.75 active=33737 feature_norm=227.10\n",
      "Iter 70  time=0.78  loss=12217.71 active=33632 feature_norm=227.06\n",
      "Iter 71  time=0.73  loss=12207.65 active=33523 feature_norm=227.07\n",
      "Iter 72  time=0.82  loss=12198.46 active=33413 feature_norm=226.99\n",
      "Iter 73  time=0.76  loss=12189.06 active=33277 feature_norm=226.98\n",
      "Iter 74  time=0.83  loss=12180.30 active=33153 feature_norm=226.86\n",
      "Iter 75  time=0.72  loss=12171.44 active=33035 feature_norm=226.84\n",
      "Iter 76  time=0.60  loss=12163.38 active=32927 feature_norm=226.75\n",
      "Iter 77  time=0.59  loss=12154.97 active=32855 feature_norm=226.71\n",
      "Iter 78  time=0.58  loss=12147.35 active=32788 feature_norm=226.60\n",
      "Iter 79  time=0.60  loss=12139.24 active=32703 feature_norm=226.56\n",
      "Iter 80  time=0.58  loss=12132.11 active=32587 feature_norm=226.45\n",
      "Iter 81  time=0.58  loss=12124.76 active=32505 feature_norm=226.42\n",
      "Iter 82  time=0.61  loss=12118.21 active=32435 feature_norm=226.32\n",
      "Iter 83  time=0.69  loss=12111.42 active=32337 feature_norm=226.30\n",
      "Iter 84  time=0.67  loss=12105.19 active=32226 feature_norm=226.21\n",
      "Iter 85  time=0.65  loss=12099.16 active=32152 feature_norm=226.22\n",
      "Iter 86  time=0.64  loss=12093.59 active=32085 feature_norm=226.14\n",
      "Iter 87  time=0.61  loss=12088.08 active=32044 feature_norm=226.16\n",
      "Iter 88  time=0.68  loss=12082.73 active=31967 feature_norm=226.11\n",
      "Iter 89  time=0.62  loss=12077.54 active=31865 feature_norm=226.13\n",
      "Iter 90  time=0.58  loss=12072.61 active=31818 feature_norm=226.07\n",
      "Iter 91  time=0.66  loss=12067.75 active=31774 feature_norm=226.13\n",
      "Iter 92  time=0.61  loss=12063.20 active=31744 feature_norm=226.10\n",
      "Iter 93  time=0.59  loss=12058.69 active=31702 feature_norm=226.14\n",
      "Iter 94  time=0.58  loss=12054.67 active=31653 feature_norm=226.12\n",
      "Iter 95  time=0.65  loss=12051.11 active=31608 feature_norm=226.19\n",
      "Iter 96  time=0.58  loss=12046.47 active=31570 feature_norm=226.18\n",
      "Iter 97  time=0.63  loss=12042.66 active=31541 feature_norm=226.24\n",
      "Iter 98  time=0.58  loss=12039.04 active=31504 feature_norm=226.24\n",
      "Iter 99  time=0.63  loss=12036.00 active=31446 feature_norm=226.29\n",
      "Iter 100 time=0.71  loss=12032.67 active=31386 feature_norm=226.29\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 68.938\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 31386 (65615)\n",
      "Number of active attributes: 18964 (45741)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None,\n",
       "  c1=0.1286420400585254, c2=0.040071684090734375,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(trainvalFeatures, trainvalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved.\n"
     ]
    }
   ],
   "source": [
    "# SAVE CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/crf7.pickle', 'wb') as outfile:\n",
    "    pickle.dump(crf, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CONDITIONAL RANDOM FIELDS MODEL\n",
    "with open('model/crf7.pickle', 'rb') as infile:\n",
    "    crf = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TRAINVAL CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    LOCATION       0.98      0.99      0.98      9409\n",
      "ORGANIZATION       0.98      0.97      0.97      9034\n",
      "        DATE       0.91      0.94      0.93      3103\n",
      "      PERSON       0.99      0.98      0.99     14476\n",
      "       MONEY       0.99      0.98      0.98       594\n",
      "     PERCENT       1.00      1.00      1.00       617\n",
      "        TIME       1.00      1.00      1.00       175\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     37408\n",
      "   macro avg       0.98      0.98      0.98     37408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainvalPredLabels = crf.predict(trainvalFeatures)\n",
    "\n",
    "print(\"### TRAINVAL CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(trainvalLabels, trainvalPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TEST CLASSIFICATION REPORT ###\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    LOCATION       0.88      0.84      0.86      1091\n",
      "ORGANIZATION       0.83      0.78      0.81       862\n",
      "      PERSON       0.90      0.84      0.87      1594\n",
      "     PERCENT       0.98      0.92      0.95       107\n",
      "        DATE       0.81      0.87      0.84       364\n",
      "       MONEY       0.88      0.74      0.81       113\n",
      "        TIME       0.90      0.78      0.84        23\n",
      "\n",
      "   micro avg       0.88      0.83      0.85      4154\n",
      "   macro avg       0.88      0.83      0.85      4154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredLabels  = crf.predict(testFeatures)\n",
    "\n",
    "print(\"### TEST CLASSIFICATION REPORT ###\\n\")\n",
    "print(classification_report(testLabels, testPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutting down the JVM\n",
    "jp.shutdownJVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
